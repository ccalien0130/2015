import pandas as pd
import random
import requests
from bs4 import BeautifulSoup
from urllib.error import URLError
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError

# â† é‡‘é‘°ï¼ˆè¦åŠ é›™å¼•è™Ÿï¼‰
API_KEY = "AIzaSyD41pjpNTOBZNbb9Y5BaizeDEugqySY8oI"

# åˆå§‹åŒ– YouTube API client
youtube = build("youtube", "v3", developerKey=API_KEY)

# ç¯„åœè¨­å®š
years = list(range(2000, 2025))
billboard_base = "https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_{}"
kkbox_base    = "https://kma.kkbox.com/charts/yearly/song?terr=tw&lang=tc&year={}"

# 1. æŠ“ Billboard å¹´çµ‚æ¦œ
dfs_en = []
for y in years:
    try:
        df_year = pd.read_html(billboard_base.format(y), header=0)[0]
        if 'Title' in df_year.columns and 'Artist(s)' in df_year.columns:
            df_year = df_year[['Title', 'Artist(s)']].rename(
                columns={'Title':'title','Artist(s)':'artist'}
            )
            dfs_en.append(df_year)
    except (ValueError, URLError):
        continue
df_en = pd.concat(dfs_en, ignore_index=True)

# 2. æŠ“ KKBOX å¹´åº¦é¢¨é›²æ¦œ
dfs_cn = []
for y in years:
    try:
        df_year = pd.read_html(kkbox_base.format(y), header=0)[0]
        if 'æ­Œæ›²' in df_year.columns and 'æ¼”å”±' in df_year.columns:
            df_year = df_year[['æ­Œæ›²','æ¼”å”±']].head(50).rename(
                columns={'æ­Œæ›²':'title','æ¼”å”±':'artist'}
            )
            dfs_cn.append(df_year)
    except (ValueError, URLError):
        continue
df_cn = pd.concat(dfs_cn, ignore_index=True) if dfs_cn else pd.DataFrame(columns=['title','artist'])

# 3. åˆä½µä¸¦å»é‡
df = pd.concat([df_en, df_cn], ignore_index=True) \
       .drop_duplicates(subset=['title','artist']) \
       .reset_index(drop=True)

# 4. éš¨æ©ŸæŠ½æ¨£ 1000 é¦–
df = df.sample(n=1000, random_state=42).reset_index(drop=True)

# 5. éš¨æ©Ÿå¥—ç”¨æƒ…ç·’ã€æ™‚é–“ã€æ´»å‹•æ¨™ç±¤
moods = ["Joyful","Cathartic","Calm","Comforting","Empowering",
         "Romantic","Melancholic","Nostalgic","Excited","Mysterious"]
times = ["morning","afternoon","evening","night"]
acts  = ["relaxing","reflecting","commuting","cooking","date","exercising","journaling"]

df['mood']        = [random.choice(moods) for _ in range(len(df))]
df['time_of_day'] = [random.choice(times) for _ in range(len(df))]
df['activity']    = [random.choice(acts)  for _ in range(len(df))]

# â”€â”€â”€ å®‰è£å‰ç½®å¥—ä»¶ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# python3 -m pip install youtube-search-python

from youtubesearchpython import VideosSearch

# â”€â”€â”€ 6. ä½¿ç”¨ youtube-search-python å–å¾—çœŸå¯¦é€£çµ â”€â”€â”€â”€â”€â”€â”€â”€
def fetch_video_link(query: str) -> str:
    """ä½¿ç”¨ VideosSearch æŠ“å–ç¬¬ä¸€æ”¯å½±ç‰‡é€£çµ"""
    vs = VideosSearch(query, limit=1)
    results = vs.result().get('result', [])
    if results:
        video_id = results[0]['id']
        return f"https://www.youtube.com/watch?v={video_id}"
    return ""

links = []
total = len(df)
for i, row in enumerate(df.itertuples(), 1):
    link = fetch_video_link(f"{row.title} {row.artist}")
    links.append(link)
    if i % 100 == 0 or i == total:
        print(f"ğŸ”— å·²è™•ç† {i}/{total} é¦–æ­Œçš„é€£çµ")
df['youtube_link'] = links

# 7. åŠ ä¸Šç·¨è™Ÿä¸¦è¼¸å‡º CSV
df.insert(0, 'song_id', range(1, len(df)+1))
df.to_csv('music_1000_with_links.csv', index=False, encoding='utf-8-sig')

print("âœ… å·²ç”Ÿæˆ music_1000_with_links.csvï¼Œå« 1000 é¦–æ­Œæ›²èˆ‡æ­£ç¢ºå½±ç‰‡é€£çµ")
